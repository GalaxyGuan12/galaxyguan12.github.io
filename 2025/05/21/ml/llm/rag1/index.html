<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"galaxyguan12.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.23.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="è¿™ç¯‡æ–‡ç« æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªadvanced RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼Œæ¥å›ç­”ç”¨æˆ·å…³äºç‰¹å®šçŸ¥è¯†åº“ï¼ˆè¿™é‡Œæ˜¯ HuggingFace ä¸­ç›¸å…³æ–‡æ¡£ï¼‰çš„é—®é¢˜ï¼Œæ–‡ç« ä»£ç ä½¿ç”¨äº† LangChainã€‚è¦äº†è§£ RAG çš„åŸºæœ¬å†…å®¹å’Œä»‹ç»ï¼Œå¯ä»¥æŸ¥çœ‹è¿™ç¯‡æ–‡ç« ã€‚RAG ç³»ç»Ÿå¾ˆå¤æ‚ï¼ŒåŒ…å«å¾ˆå¤šéƒ¨åˆ†ï¼Œä¸‹å›¾æè¿°äº† RAG ä¸­çš„å…³é”®éƒ¨åˆ†ï¼Œè“è‰²æ ‡æ³¨çš„å†…å®¹æ˜¯å¯ä»¥è¢«æŒç»­ä¼˜åŒ–çš„ã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="RAGå…¨æµç¨‹è§£æ">
<meta property="og:url" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/index.html">
<meta property="og:site_name" content="é€’å½’ä¹¦æˆ¿">
<meta property="og:description" content="è¿™ç¯‡æ–‡ç« æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªadvanced RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼Œæ¥å›ç­”ç”¨æˆ·å…³äºç‰¹å®šçŸ¥è¯†åº“ï¼ˆè¿™é‡Œæ˜¯ HuggingFace ä¸­ç›¸å…³æ–‡æ¡£ï¼‰çš„é—®é¢˜ï¼Œæ–‡ç« ä»£ç ä½¿ç”¨äº† LangChainã€‚è¦äº†è§£ RAG çš„åŸºæœ¬å†…å®¹å’Œä»‹ç»ï¼Œå¯ä»¥æŸ¥çœ‹è¿™ç¯‡æ–‡ç« ã€‚RAG ç³»ç»Ÿå¾ˆå¤æ‚ï¼ŒåŒ…å«å¾ˆå¤šéƒ¨åˆ†ï¼Œä¸‹å›¾æè¿°äº† RAG ä¸­çš„å…³é”®éƒ¨åˆ†ï¼Œè“è‰²æ ‡æ³¨çš„å†…å®¹æ˜¯å¯ä»¥è¢«æŒç»­ä¼˜åŒ–çš„ã€‚">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/d05ef3bf13d879bf2560a30566164974.png">
<meta property="og:image" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/chunk_sizes_char.png">
<meta property="og:image" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/%E6%88%AA%E5%B1%8F2025-05-21%2015.22.24.png">
<meta property="og:image" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/chunk_sizes2.png">
<meta property="og:image" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/embedding_projection.png">
<meta property="article:published_time" content="2025-05-21T14:36:39.000Z">
<meta property="article:modified_time" content="2025-06-29T23:59:12.994Z">
<meta property="article:author" content="GalaxyGuan">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/d05ef3bf13d879bf2560a30566164974.png">


<link rel="canonical" href="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/","path":"2025/05/21/ml/llm/rag1/","title":"RAGå…¨æµç¨‹è§£æ"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>RAGå…¨æµç¨‹è§£æ | é€’å½’ä¹¦æˆ¿</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">é€’å½’ä¹¦æˆ¿</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">GalaxyGuan's Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">1.</span> <span class="nav-text">ç¯å¢ƒå‡†å¤‡</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A0%E8%BD%BD"><span class="nav-number">2.</span> <span class="nav-text">çŸ¥è¯†åº“åŠ è½½</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Retriever-embeddings-%F0%9F%97%82%EF%B8%8F"><span class="nav-number">3.</span> <span class="nav-text">1. Retriever - embeddings ğŸ—‚ï¸</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E5%B0%86%E6%96%87%E6%A1%A3%E6%8B%86%E5%88%86%E4%B8%BAchunks"><span class="nav-number">3.1.</span> <span class="nav-text">1.1 å°†æ–‡æ¡£æ‹†åˆ†ä¸ºchunks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="nav-number">3.2.</span> <span class="nav-text">1.2 è¯åµŒå…¥</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-%E6%9E%84%E5%BB%BA%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">3.3.</span> <span class="nav-text">1.3 æ„å»ºå‘é‡æ•°æ®åº“</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Nearest-Neighbor-search-algorithm-%EF%BC%88%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%EF%BC%89"><span class="nav-number">3.3.1.</span> <span class="nav-text">Nearest Neighbor search algorithm ï¼ˆæœ€è¿‘é‚»æœç´¢ç®—æ³•ï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distances-%EF%BC%88%E8%B7%9D%E7%A6%BB%EF%BC%89"><span class="nav-number">3.3.2.</span> <span class="nav-text">Distances ï¼ˆè·ç¦»ï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%82%B9%E7%A7%AF%EF%BC%88Dot-Product%EF%BC%89%EF%BC%9A"><span class="nav-number">3.3.2.1.</span> <span class="nav-text">ç‚¹ç§¯ï¼ˆDot Productï¼‰ï¼š</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%88Cosine-Similarity%EF%BC%89%EF%BC%9A"><span class="nav-number">3.3.2.2.</span> <span class="nav-text">ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰ï¼š</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB%EF%BC%88Euclidean-Distance%EF%BC%89%E5%85%AC%E5%BC%8F"><span class="nav-number">3.3.2.3.</span> <span class="nav-text">æ¬§å¼è·ç¦»ï¼ˆEuclidean Distanceï¼‰å…¬å¼</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-%E9%87%8D%E6%8E%92%E5%BA%8F-Reranking"><span class="nav-number">3.4.</span> <span class="nav-text">1.4 é‡æ’åº(Reranking)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Colbertv2"><span class="nav-number">3.4.1.</span> <span class="nav-text">Colbertv2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bi-encoder-vs-Cross-encoder"><span class="nav-number">3.4.2.</span> <span class="nav-text">Bi-encoder vs Cross-encoder</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Reader-LLM-%F0%9F%92%AC"><span class="nav-number">4.</span> <span class="nav-text">2. Reader - LLM ğŸ’¬</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Reader-model"><span class="nav-number">4.1.</span> <span class="nav-text">2.1. Reader model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Prompt"><span class="nav-number">4.2.</span> <span class="nav-text">2.2. Prompt</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.3.</span> <span class="nav-text"></span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E5%86%85%E5%AE%B9%E6%95%B4%E5%90%88"><span class="nav-number">5.</span> <span class="nav-text">3. å†…å®¹æ•´åˆ</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="GalaxyGuan"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">GalaxyGuan</p>
  <div class="site-description" itemprop="description">ç”¨é€’å½’è¿½æº¯é—®é¢˜æœ¬è´¨</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/gdr12?type=blog" title="CSDN â†’ https:&#x2F;&#x2F;blog.csdn.net&#x2F;gdr12?type&#x3D;blog" rel="noopener me" target="_blank"><i class="fa-solid fa-blog fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/GalaxyGuan12" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;GalaxyGuan12" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/dengrongguan12@gmail.com" title="E-Mail â†’ dengrongguan12@gmail.com" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/images/wechat.jpg" title="WeChat â†’ &#x2F;images&#x2F;wechat.jpg" rel="noopener me"><i class="fab fa-weixin fa-fw"></i>WeChat</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/DarrenGuan" title="Zhihu â†’ https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;DarrenGuan" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/rerelaxguan" title="Twitter â†’ https:&#x2F;&#x2F;x.com&#x2F;rerelaxguan" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="GalaxyGuan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="é€’å½’ä¹¦æˆ¿">
      <meta itemprop="description" content="ç”¨é€’å½’è¿½æº¯é—®é¢˜æœ¬è´¨">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="RAGå…¨æµç¨‹è§£æ | é€’å½’ä¹¦æˆ¿">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          RAGå…¨æµç¨‹è§£æ
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-05-21 22:36:39" itemprop="dateCreated datePublished" datetime="2025-05-21T22:36:39+08:00">2025-05-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">æœºå™¨å­¦ä¹ </span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">å¤§è¯­è¨€æ¨¡å‹</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>è¿™ç¯‡æ–‡ç« æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªadvanced RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼Œæ¥å›ç­”ç”¨æˆ·å…³äºç‰¹å®šçŸ¥è¯†åº“ï¼ˆè¿™é‡Œæ˜¯ HuggingFace ä¸­ç›¸å…³æ–‡æ¡£ï¼‰çš„é—®é¢˜ï¼Œæ–‡ç« ä»£ç ä½¿ç”¨äº† LangChainã€‚<br>è¦äº†è§£ RAG çš„åŸºæœ¬å†…å®¹å’Œä»‹ç»ï¼Œå¯ä»¥æŸ¥çœ‹<a target="_blank" rel="noopener" href="https://huggingface.co/learn/cookbook/rag_zephyr_langchain">è¿™ç¯‡æ–‡ç« </a>ã€‚<br>RAG ç³»ç»Ÿå¾ˆå¤æ‚ï¼ŒåŒ…å«å¾ˆå¤šéƒ¨åˆ†ï¼Œä¸‹å›¾æè¿°äº† RAG ä¸­çš„å…³é”®éƒ¨åˆ†ï¼Œè“è‰²æ ‡æ³¨çš„å†…å®¹æ˜¯å¯ä»¥è¢«æŒç»­ä¼˜åŒ–çš„ã€‚</p>
<span id="more"></span>


<p><img src="/2025/05/21/ml/llm/rag1/d05ef3bf13d879bf2560a30566164974.png"></p>
<blockquote>
<p>ğŸ’¡ ä»ä¸Šå›¾èƒ½çœ‹å‡ºæ¥ï¼ŒRAG æ¶æ„ä¸­æœ‰è®¸å¤šæ­¥éª¤æ˜¯å¯ä»¥ä¼˜åŒ–çš„ï¼Œæ­£ç¡®çš„ä¼˜åŒ–ä¼šå¸¦æ¥æ˜¾è‘—çš„æ•ˆæœæå‡ã€‚</p>
</blockquote>
<p>åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä¼šé‡ç‚¹å…³æ³¨è“è‰²å†…å®¹ï¼Œæ¥è°ƒæ•´æˆ‘ä»¬è‡ªå·±çš„ RAG ç³»ç»Ÿæ¥è·å¾—æœ€ä½³æ•ˆæœã€‚</p>
<p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬æŠŠæ‰‹å¼„è„ï¼Œç›´æ¥è·Ÿç€æ–‡ç« çš„æ€è·¯æ¥äº†è§£RAGçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚</p>
<h1 id="ç¯å¢ƒå‡†å¤‡"><a href="#ç¯å¢ƒå‡†å¤‡" class="headerlink" title="ç¯å¢ƒå‡†å¤‡"></a>ç¯å¢ƒå‡†å¤‡</h1><p>åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è£…å¥½å¦‚ä¸‹ä¾èµ–ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å»ºè®®ä½¿ç”¨condaåˆ›å»ºä¸€ä¸ªå¹²å‡€çš„è™šæ‹Ÿç¯å¢ƒ</span></span><br><span class="line">conda create --name huggingface python=3.10 -y</span><br><span class="line">conda activate huggingface</span><br><span class="line">pip install torch transformers accelerate bitsandbytes langchain sentence-transformers openpyxl pacmap datasets langchain-community ragatouille faiss</span><br></pre></td></tr></table></figure>

<p>faisså®‰è£…å¯èƒ½ä¼šå‡ºç°é—®é¢˜ï¼Œè§£å†³æ–¹æ¡ˆ:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ pip install faiss-cpu</span><br><span class="line"><span class="comment"># or: </span></span><br><span class="line">$ pip install faiss-gpu-cu12 <span class="comment"># CUDA 12.x, Python 3.8+</span></span><br><span class="line">$ pip install faiss-gpu-cu11 <span class="comment"># CUDA 11.x, Python 3.8+</span></span><br><span class="line">$ pip install faiss-gpu <span class="comment"># Python 3.6-3.10 (legacy, no longer available after version 1.7.3)</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>torchã€cuda ç­‰å®‰è£…éªŒè¯åŠç‰ˆæœ¬æŸ¥çœ‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># è·å– PyTorch ç‰ˆæœ¬ä¿¡æ¯</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;PyTorch Version: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.version.__version__))  <span class="comment"># æˆ–ç›´æ¥ä½¿ç”¨ torch.__version__</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;PyTorch CUDA Version: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.version.cuda))  <span class="comment"># è·å– CUDA ç‰ˆæœ¬</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;PyTorch cuDNN Version: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.backends.cudnn.version()))  <span class="comment"># è·å– cuDNN ç‰ˆæœ¬</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>å› ä¸ºåœ¨æ–‡ç« ä»£ç ä¸­ä¼šè‡ªåŠ¨ä¸‹è½½huggingfaceä¸Šçš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä¼šé»˜è®¤å­˜å‚¨åœ¨~&#x2F;.cache&#x2F;huggingfaceç›®å½•ä¸‹ã€‚å¦‚æœä½ æ‹…å¿ƒç³»ç»Ÿç›˜ä¸å¤Ÿå­˜å‚¨è¿™äº›æ•°æ®ï¼Œä½ ä¹Ÿå¯ä»¥ä¿®æ”¹huggingface cacheçš„é»˜è®¤æ ¹ç›®å½•ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HF_HOME=<span class="string">&quot;/&#123;to_path&#125;/huggingface&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸ºäº†ä¸ç”¨æ¯æ¬¡éƒ½æ‰§è¡Œï¼Œä½ å¯ä»¥ç›´æ¥å†™å…¥bashé…ç½®</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export HF_HOME=&quot;/&#123;to_path&#125;/huggingface&quot;&#x27;</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>å¦å¤–ï¼Œå›½å†…è®¿é—®huggingfaceæ˜¯å—é™çš„ï¼ˆå¢™ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨huggingface å›½å†…é•œåƒç«™è¿è¡Œpythonè„šæœ¬:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HF_ENDPOINT=https://hf-mirror.com python advanced_rag.py</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span>, <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">pd.set_option(<span class="string">&quot;display.max_colwidth&quot;</span>, <span class="literal">None</span>) <span class="comment"># This will be helpful when visualizing retriever outputs </span></span><br></pre></td></tr></table></figure>



<h1 id="çŸ¥è¯†åº“åŠ è½½"><a href="#çŸ¥è¯†åº“åŠ è½½" class="headerlink" title="çŸ¥è¯†åº“åŠ è½½"></a>çŸ¥è¯†åº“åŠ è½½</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line">ds = datasets.load_dataset(<span class="string">&quot;m-ric/huggingface_doc&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> langchain.docstore.document <span class="keyword">import</span> Document <span class="keyword">as</span> LangchainDocument</span><br><span class="line">RAW_KNOWLEDGE_BASE = [</span><br><span class="line">        LangchainDocument(page_content=doc[<span class="string">&quot;text&quot;</span>], metadata=&#123;<span class="string">&quot;source&quot;</span>: doc[<span class="string">&quot;source&quot;</span>]&#125;) <span class="keyword">for</span> doc <span class="keyword">in</span> tqdm(ds)</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>



<h1 id="1-Retriever-embeddings-ğŸ—‚ï¸"><a href="#1-Retriever-embeddings-ğŸ—‚ï¸" class="headerlink" title="1. Retriever - embeddings ğŸ—‚ï¸"></a>1. Retriever - embeddings ğŸ—‚ï¸</h1><p><strong>retriever</strong>åƒä¸€ä¸ªå†…ç½®çš„æœç´¢å¼•æ“ï¼šæ¥æ”¶ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œè¿”å›çŸ¥è¯†åº“ä¸­çš„ä¸€äº›ç›¸å…³ç‰‡æ®µã€‚è¿™äº›ç‰‡æ®µä¼šè¾“å…¥åˆ°Reader Modelï¼ˆå¦‚deepseekï¼‰ä¸­ï¼Œæ¥å¸®åŠ©å®ƒç”Ÿæˆç­”æ¡ˆã€‚å› æ­¤ï¼Œç°åœ¨æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯ï¼ŒåŸºäºç”¨æˆ·çš„é—®é¢˜ï¼Œä»æˆ‘ä»¬çš„çŸ¥è¯†åº“ä¸­æ‰¾åˆ°æœ€ç›¸å…³çš„ç‰‡æ®µæ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªå®½æ³›çš„ç›®æ ‡ï¼Œå®ƒå¼•ç”³å‡ºäº†ä¸€å †é—®é¢˜ã€‚æ¯”å¦‚æˆ‘ä»¬åº”è¯¥æ£€ç´¢å¤šå°‘ä¸ªç‰‡æ®µï¼Ÿè¿™ä¸ªå…³äºç‰‡æ®µæ•°é‡çš„å‚æ•°å°±è¢«å‘½åä¸º <code>top_k</code> ã€‚å†æ¯”å¦‚ï¼Œæ¯ä¸ªç‰‡æ®µåº”è¯¥æœ‰å¤šé•¿ï¼Ÿè¿™ä¸ªç‰‡æ®µé•¿åº¦çš„å‚æ•°å°±è¢«ç§°ä¸º <code>chunk size</code> ã€‚è¿™äº›é—®é¢˜æ²¡æœ‰å”¯ä¸€çš„é€‚åˆæ‰€æœ‰æƒ…å†µçš„ç­”æ¡ˆï¼Œä½†æœ‰ä¸€äº›ç›¸å…³çŸ¥è¯†æˆ‘ä»¬å¯ä»¥äº†è§£ä¸‹ï¼š</p>
<ul>
<li><p>ğŸ”€  ä¸åŒçš„ç‰‡æ®µå¯ä»¥æœ‰ä¸åŒçš„<code>chunk size</code> ã€‚</p>
</li>
<li><p>ç”±äºæ£€ç´¢å†…å®¹ä¸­æ€»ä¼šæœ‰ä¸€äº›å™ªéŸ³ï¼Œå¢åŠ  <code>top_k</code> çš„å€¼ä¼šå¢åŠ åœ¨æ£€ç´¢åˆ°çš„ç‰‡æ®µä¸­è·å¾—ç›¸å…³å†…å®¹çš„æœºä¼šã€‚ç±»ä¼¼å°„ç®­ğŸ¯ï¼Œ å°„å‡ºæ›´å¤šçš„ç®­ä¼šå¢åŠ ä½ å‡»ä¸­ç›®æ ‡çš„æ¦‚ç‡ã€‚</p>
</li>
<li><p>åŒæ—¶ï¼Œæ£€ç´¢åˆ°çš„æ–‡æ¡£çš„æ€»é•¿åº¦ä¸åº”å¤ªé•¿ï¼šæ¯”å¦‚ï¼Œå¯¹äºç›®å‰å¤§å¤šæ•°çš„æ¨¡å‹ï¼Œ16kçš„tokenæ•°é‡å¯èƒ½ä¼šè®©æ¨¡å‹å› ä¸ºâ€œ<a target="_blank" rel="noopener" href="https://hf-mirror.com/papers/2307.03172">Lost in the middle phenomemon</a>â€è€Œæ·¹æ²¡åœ¨ä¿¡æ¯ä¸­ã€‚æ‰€ä»¥ï¼Œåªç»™æ¨¡å‹æä¾›æœ€ç›¸å…³çš„è§è§£ï¼Œè€Œä¸æ˜¯ä¸€å¤§å †å†…å®¹ï¼</p>
</li>
</ul>
<blockquote>
<p>åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ Langchain åº“ï¼Œå› ä¸ºå®ƒæä¾›äº†å¤§é‡çš„å‘é‡æ•°æ®åº“é€‰é¡¹ï¼Œå¹¶å…è®¸æˆ‘ä»¬åœ¨å¤„ç†è¿‡ç¨‹ä¸­ä¿æŒæ–‡æ¡£çš„å…ƒæ•°æ®ã€‚</p>
</blockquote>
<h2 id="1-1-å°†æ–‡æ¡£æ‹†åˆ†ä¸ºchunks"><a href="#1-1-å°†æ–‡æ¡£æ‹†åˆ†ä¸ºchunks" class="headerlink" title="1.1 å°†æ–‡æ¡£æ‹†åˆ†ä¸ºchunks"></a>1.1 å°†æ–‡æ¡£æ‹†åˆ†ä¸ºchunks</h2><p>åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£æ‹†åˆ†ä¸ºæ›´å°çš„chunksï¼Œchat LLM ä¼šåŸºäºè¿™äº›chunksè¿›è¡Œå›ç­”ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¾—åˆ°ä¸€ç»„è¯­ä¹‰ç›¸å…³çš„ç‰‡æ®µã€‚å› æ­¤ï¼Œå®ƒä»¬çš„å¤§å°éœ€è¦é€‚åº”å…·ä½“çš„ä¸»é¢˜æˆ–è€…è¯´æ˜¯ä¸­å¿ƒæ€æƒ³ï¼šå¤ªå°çš„è¯ä¼šæˆªæ–­ä¸­å¿ƒæ€æƒ³ï¼Œå¤ªå¤§å¯èƒ½å°±ä¼šç¨€é‡Šä¸­å¿ƒæ€æƒ³ï¼Œè¢«å…¶ä»–ä¸ç›¸å…³å†…å®¹å¹²æ‰°ã€‚</p>
<blockquote>
<p>ğŸ’¡ ç°åœ¨æœ‰è®¸å¤šæ‹†åˆ†æ–‡æœ¬å†…å®¹çš„æ–¹æ¡ˆï¼Œæ¯”å¦‚ï¼šæŒ‰è¯æ‹†åˆ†ã€æŒ‰å¥å­è¾¹ç•Œæ‹†åˆ†ã€é€’å½’æ‹†åˆ†ï¼ˆä»¥æ ‘çŠ¶æ–¹å¼å¤„ç†æ–‡æ¡£ä»¥ä¿ç•™ç»“æ„ä¿¡æ¯ï¼‰â€¦â€¦è¦äº†è§£æ›´å¤šå…³äºæ–‡æœ¬æ‹†åˆ†çš„å†…å®¹ï¼Œå¯ä»¥å‚è€ƒ<a target="_blank" rel="noopener" href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb">è¿™ç¯‡æ–‡æ¡£</a>ã€‚</p>
</blockquote>
<p>é€’å½’åˆ†å—é€šè¿‡ä½¿ç”¨ä¸€ç»„æŒ‰é‡è¦æ€§æ’åºçš„åˆ†éš”ç¬¦ï¼Œå°†æ–‡æœ¬é€æ­¥åˆ†è§£ä¸ºæ›´å°çš„éƒ¨åˆ†ã€‚å¦‚æœç¬¬ä¸€æ¬¡æ‹†åˆ†æ²¡æœ‰ç»™å‡ºæ­£ç¡®å¤§å°çš„å—ï¼Œå®ƒå°±ä¼šåœ¨æ–°çš„å—ä¸Šä½¿ç”¨ä¸åŒçš„åˆ†éš”ç¬¦æ¥é‡å¤è¿™ä¸ªæ­¥éª¤ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™æ ·çš„åˆ†éš”ç¬¦åˆ—è¡¨ <code>[&quot;\n\n&quot;, &quot;\n&quot;, &quot;.&quot;, &quot;&quot;]</code> ï¼š</p>
<p>è¿™ç§æ–¹æ³•å¾ˆå¥½çš„ä¿ç•™äº†æ–‡æ¡£çš„æ•´ä½“ç»“æ„ï¼Œä½†ä»£ä»·æ˜¯å—å¤§å°ä¼šæœ‰è½»å¾®çš„å˜åŒ–ã€‚</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/A-Roucher/chunk_visualizer">è¿™é‡Œ</a>å¯ä»¥è®©ä½ çœ‹åˆ°ä¸åŒçš„æ‹†åˆ†é€‰é¡¹ä¼šå¦‚ä½•å½±å“ä½ å¾—åˆ°çš„å—ã€‚</p>
</blockquote>
<p>ğŸ”¬ è®©æˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªä»»æ„å¤§å°çš„å—æ¥åšä¸€ä¸ªå®éªŒï¼Œçœ‹çœ‹æ‹†åˆ†å…·ä½“æ˜¯æ€ä¹ˆå·¥ä½œçš„ã€‚æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ Langchain çš„é€’å½’æ‹†åˆ†ç±» <code>RecursiveCharacterTextSplitter</code> ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line"><span class="comment"># We use a hierarchical list of separators specifically tailored for splitting Markdown documents</span></span><br><span class="line"><span class="comment"># This list is taken from LangChain&#x27;s MarkdownTextSplitter class</span></span><br><span class="line">MARKDOWN_SEPARATORS = [</span><br><span class="line">    <span class="string">&quot;\n#&#123;1,6&#125; &quot;</span>,</span><br><span class="line">    <span class="string">&quot;```\n&quot;</span>,</span><br><span class="line">    <span class="string">&quot;\n\\*\\*\\*+\n&quot;</span>,</span><br><span class="line">    <span class="string">&quot;\n---+\n&quot;</span>,</span><br><span class="line">    <span class="string">&quot;\n___+\n&quot;</span>,</span><br><span class="line">    <span class="string">&quot;\n\n&quot;</span>,</span><br><span class="line">    <span class="string">&quot;\n&quot;</span>,</span><br><span class="line">    <span class="string">&quot; &quot;</span>,</span><br><span class="line">    <span class="string">&quot;&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">1000</span>,  <span class="comment"># The maximum number of characters in a chunk: we selected this value arbitrarily</span></span><br><span class="line">    chunk_overlap=<span class="number">100</span>,  <span class="comment"># The number of characters to overlap between chunks</span></span><br><span class="line">    add_start_index=<span class="literal">True</span>,  <span class="comment"># If `True`, includes chunk&#x27;s start index in metadata</span></span><br><span class="line">    strip_whitespace=<span class="literal">True</span>,  <span class="comment"># If `True`, strips whitespace from the start and end of every document</span></span><br><span class="line">    separators=MARKDOWN_SEPARATORS,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">docs_processed = []</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> RAW_KNOWLEDGE_BASE:</span><br><span class="line">    docs_processed += text_splitter.split_documents([doc])</span><br></pre></td></tr></table></figure>

<ul>
<li><p>å…¶ä¸­ï¼Œå‚æ•° <code>chunk_size</code> æ§åˆ¶å•ä¸ªå—çš„é•¿åº¦ï¼šè¿™ä¸ªé•¿åº¦é»˜è®¤æ˜¯æŒ‰å—ä¸­çš„å­—ç¬¦æ•°æ¥è®¡ç®—çš„ã€‚</p>
</li>
<li><p>å‚æ•° <code>chunk_overlap</code> æ˜¯ä¸ºäº†å…è®¸ç›¸é‚»çš„å—ä¹‹é—´æœ‰ä¸€äº›é‡å ï¼Œè¿™èƒ½å¤Ÿå‡å°‘ä¸€ä¸ªä¸»é¢˜å¯èƒ½åœ¨ä¸¤ä¸ªç›¸é‚»å—çš„åˆ†å‰²ä¸­è¢«åˆ‡æˆä¸¤åŠçš„æ¦‚ç‡ã€‚æˆ‘ä»¬æŠŠå®ƒè®¾ç½®ä¸ºå—å¤§å°çš„ 1&#x2F;10ï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥è‡ªå·±å°è¯•å…¶ä»–ä¸åŒçš„å€¼ï¼</p>
</li>
</ul>
<p>æˆ‘ä»¬åˆ©ç”¨ä»¥ä¸‹ä»£ç çœ‹çœ‹chunkçš„é•¿åº¦åˆ†å¸ƒï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lengths = [<span class="built_in">len</span>(doc.page_content) <span class="keyword">for</span> doc <span class="keyword">in</span> tqdm(docs_processed)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the distribution of document lengths, counted as the number of chars</span></span><br><span class="line">fig = pd.Series(lengths).hist()</span><br><span class="line">plt.title(<span class="string">&quot;Distribution of document lengths in the knowledge base (in count of chars)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>ğŸ’¡å¦‚æœä½ ä½¿ç”¨äº†è¿œç¨‹è®¾å¤‡ä¸æ”¯æŒç›´æ¥ä½¿ç”¨ <code>plt.show()</code> å¯è§†åŒ–ï¼Œå¯ä»¥æ¢æˆç”¨å¦‚ä¸‹ä»£ç ç›´æ¥ä¿å­˜æˆå›¾ç‰‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.savefig(<span class="string">&quot;chunk_sizes_char.png&quot;</span>, dpi=<span class="number">300</span>, bbox_inches=<span class="string">&quot;tight&quot;</span>)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>å¯è§†åŒ–ç»“æœå¦‚ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æœ€å¤§çš„å—çš„å­—ç¬¦é•¿åº¦ä¸ä¼šè¶…è¿‡1000ï¼Œè¿™å’Œæˆ‘ä»¬é¢„å…ˆè®¾ç½®çš„å‚æ•°ä¸€è‡´ã€‚</p>
<p><img src="/2025/05/21/ml/llm/rag1/chunk_sizes_char.png"></p>
<h2 id="1-2-è¯åµŒå…¥"><a href="#1-2-è¯åµŒå…¥" class="headerlink" title="1.2 è¯åµŒå…¥"></a>1.2 è¯åµŒå…¥</h2><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨è¯åµŒå…¥æ¨¡å‹æ¥å¯¹åˆ†å—è¿›è¡Œå‘é‡åŒ–ã€‚åœ¨ä½¿ç”¨è¯åµŒå…¥æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“æ¨¡å‹èƒ½æ¥å—çš„æœ€å¤§åºåˆ—é•¿åº¦<code>max_seq_length</code>ï¼ˆæŒ‰ç…§tokenæ•°ç»Ÿè®¡ï¼‰ã€‚éœ€è¦ç¡®ä¿åˆ†å—çš„tokenæ•°ä½äºè¿™ä¸ªå€¼ï¼Œå› ä¸ºè¶…è¿‡<code>max_seq_length</code>çš„å—åœ¨å¤„ç†ä¹‹å‰éƒ½ä¼šè¢«æˆªæ–­ï¼Œä»è€Œå¤±å»ç›¸å…³æ€§ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹æ˜¯<code>thenlper/gte-small</code>ï¼Œ ä¸‹é¢ä»£ç å…ˆæ‰“å°äº†è¯¥æ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦ï¼Œç„¶åå†å¯¹åˆ†å—ç»“æœè¿›è¡Œtokenæ•°é‡çš„åˆ†å¸ƒç»Ÿè®¡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line"></span><br><span class="line"><span class="comment"># To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used in the RecursiveCharacterTextSplitter</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model&#x27;s maximum sequence length: <span class="subst">&#123;SentenceTransformer(<span class="string">&#x27;thenlper/gte-small&#x27;</span>).max_seq_length&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;thenlper/gte-small&quot;</span>)</span><br><span class="line">lengths = [<span class="built_in">len</span>(tokenizer.encode(doc.page_content)) <span class="keyword">for</span> doc <span class="keyword">in</span> tqdm(docs_processed)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the distribution of document lengths, counted as the number of tokens</span></span><br><span class="line">fig = pd.Series(lengths).hist()</span><br><span class="line">plt.title(<span class="string">&quot;Distribution of document lengths in the knowledge base (in count of tokens)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>ä¸Šé¢ä»£ç ä¼šå…ˆè¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Model<span class="string">&#x27;s maximum sequence length: 512</span></span><br></pre></td></tr></table></figure>

<p>è¡¨ç¤º<code>thenlper/gte-small</code> æ”¯æŒçš„æœ€å¤§å—é•¿åº¦æ˜¯ 512</p>
<p>å¯è§†åŒ–ç»“æœå¦‚ä¸‹ï¼š</p>
<p><img src="/2025/05/21/ml/llm/rag1/%E6%88%AA%E5%B1%8F2025-05-21%2015.22.24.png"></p>
<p>ğŸ‘€ å¯ä»¥çœ‹åˆ°ï¼ŒæŸäº›åˆ†å—çš„tokenæ•°é‡è¶…è¿‡äº† 512 çš„é™åˆ¶ï¼Œè¿™æ ·å°±ä¼šå¯¼è‡´åˆ†å—ä¸­çš„ä¸€éƒ¨åˆ†å†…å®¹ä¼šå› æˆªæ–­è€Œä¸¢å¤±ï¼</p>
<ul>
<li><p>æ—¢ç„¶æ˜¯åŸºäºtokenæ•°æ¥ç»Ÿè®¡ï¼Œé‚£æˆ‘ä»¬å°±åº”è¯¥å°† <code>RecursiveCharacterTextSplitter</code> ç±»æ›´æ”¹ä¸ºä»¥tokenæ•°é‡è€Œä¸æ˜¯å­—ç¬¦æ•°é‡æ¥è®¡ç®—é•¿åº¦ã€‚</p>
</li>
<li><p>ç„¶åæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€ä¸ªç‰¹å®šçš„å—å¤§å°ï¼Œè¿™é‡Œæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªä½äº 512 çš„é˜ˆå€¼ï¼š</p>
<ul>
<li><p>è¾ƒå°çš„æ–‡æ¡£å¯ä»¥ä½¿åˆ†å—æ›´ä¸“æ³¨äºç‰¹å®šçš„ä¸»é¢˜ã€‚</p>
</li>
<li><p>ä½†è¿‡å°çš„å—åˆä¼šå°†å®Œæ•´çš„å¥å­ä¸€åˆ†ä¸ºäºŒï¼Œä»è€Œå†æ¬¡å¤±å»æ„ä¹‰ï¼Œæ‰€ä»¥è¿™ä¹Ÿéœ€è¦æˆ‘ä»¬æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œæƒè¡¡ã€‚</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">EMBEDDING_MODEL_NAME = <span class="string">&quot;thenlper/gte-small&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_documents</span>(<span class="params"></span></span><br><span class="line"><span class="params">    chunk_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    knowledge_base: <span class="type">List</span>[LangchainDocument],</span></span><br><span class="line"><span class="params">    tokenizer_name: <span class="type">Optional</span>[<span class="built_in">str</span>] = EMBEDDING_MODEL_NAME,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">List</span>[LangchainDocument]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(</span><br><span class="line">        AutoTokenizer.from_pretrained(tokenizer_name),</span><br><span class="line">        chunk_size=chunk_size,</span><br><span class="line">        chunk_overlap=<span class="built_in">int</span>(chunk_size / <span class="number">10</span>),</span><br><span class="line">        add_start_index=<span class="literal">True</span>, <span class="comment"># æ˜¯å¦åœ¨æ¯ä¸ªåˆ†å—çš„ metadata ä¸­æ·»åŠ è¯¥åˆ†å—åœ¨åŸå§‹æ–‡æ¡£ä¸­çš„èµ·å§‹å­—ç¬¦ç´¢å¼•</span></span><br><span class="line">        strip_whitespace=<span class="literal">True</span>, <span class="comment"># æ˜¯å¦å»é™¤æ¯ä¸ªåˆ†å—å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦ï¼ˆå¦‚ç©ºæ ¼ã€æ¢è¡Œç­‰ï¼‰</span></span><br><span class="line">        separators=MARKDOWN_SEPARATORS,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    docs_processed = []</span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> knowledge_base:</span><br><span class="line">        docs_processed += text_splitter.split_documents([doc])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove duplicates</span></span><br><span class="line">    unique_texts = &#123;&#125;</span><br><span class="line">    docs_processed_unique = []</span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> docs_processed:</span><br><span class="line">        <span class="keyword">if</span> doc.page_content <span class="keyword">not</span> <span class="keyword">in</span> unique_texts:</span><br><span class="line">            unique_texts[doc.page_content] = <span class="literal">True</span></span><br><span class="line">            docs_processed_unique.append(doc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> docs_processed_unique</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docs_processed = split_documents(</span><br><span class="line">    <span class="number">512</span>,  <span class="comment"># We choose a chunk size adapted to our model</span></span><br><span class="line">    RAW_KNOWLEDGE_BASE,</span><br><span class="line">    tokenizer_name=EMBEDDING_MODEL_NAME,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s visualize the chunk sizes we would have in tokens from a common model</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)</span><br><span class="line">lengths = [<span class="built_in">len</span>(tokenizer.encode(doc.page_content)) <span class="keyword">for</span> doc <span class="keyword">in</span> tqdm(docs_processed)]</span><br><span class="line">fig = pd.Series(lengths).hist()</span><br><span class="line">plt.title(<span class="string">&quot;Distribution of document lengths in the knowledge base (in count of tokens)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>å¯è§†åŒ–ç»“æœå¦‚ä¸‹å›¾ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œç°åœ¨å—é•¿åº¦çš„åˆ†å¸ƒçœ‹èµ·æ¥æ¯”ä¹‹å‰å¥½å¾ˆå¤šäº†ï¼</p>
<p><img src="/2025/05/21/ml/llm/rag1/chunk_sizes2.png"></p>
<h2 id="1-3-æ„å»ºå‘é‡æ•°æ®åº“"><a href="#1-3-æ„å»ºå‘é‡æ•°æ®åº“" class="headerlink" title="1.3 æ„å»ºå‘é‡æ•°æ®åº“"></a>1.3 æ„å»ºå‘é‡æ•°æ®åº“</h2><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ‰€æœ‰å—çš„è¯åµŒå…¥ç»“æœå­˜åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œå½“ç”¨æˆ·è¾“å…¥é—®é¢˜æ—¶ï¼Œé—®é¢˜æœ¬èº«ä¹Ÿä¼šè¢«å…ˆå‰ä½¿ç”¨çš„ç›¸åŒè¯åµŒå…¥æ¨¡å‹è¿›è¡Œè¯åµŒå…¥ï¼ˆå‘é‡åŒ–ï¼‰ï¼Œå¹¶é€šè¿‡ç›¸ä¼¼æ€§æœç´¢è¿”å›å‘é‡æ•°æ®åº“ä¸­æœ€æ¥è¿‘çš„æ–‡æ¡£ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šè¯åµŒå…¥çš„ä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒè¿™ç¯‡<a target="_blank" rel="noopener" href="https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/">æŒ‡å—</a>ã€‚è¿™é‡Œçš„éš¾ç‚¹åœ¨äºï¼Œç»™å®šä¸€ä¸ªæŸ¥è¯¢å‘é‡ï¼Œå¿«é€Ÿæ‰¾åˆ°è¯¥å‘é‡åœ¨å‘é‡æ•°æ®åº“ä¸­çš„æœ€è¿‘é‚»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ç¡®å®šä¸¤ä¸ªä¸œè¥¿ï¼šä¸€ç§è·ç¦»åº¦é‡æ–¹å¼å’Œä¸€ç§æœç´¢ç®—æ³•ï¼Œä»¥ä¾¿åœ¨æ•°åƒæ¡è®°å½•çš„æ•°æ®åº“ä¸­å¿«é€Ÿæ‰¾åˆ°æœ€è¿‘é‚»ã€‚</p>
<h3 id="Nearest-Neighbor-search-algorithm-ï¼ˆæœ€è¿‘é‚»æœç´¢ç®—æ³•ï¼‰"><a href="#Nearest-Neighbor-search-algorithm-ï¼ˆæœ€è¿‘é‚»æœç´¢ç®—æ³•ï¼‰" class="headerlink" title="Nearest Neighbor search algorithm ï¼ˆæœ€è¿‘é‚»æœç´¢ç®—æ³•ï¼‰"></a>Nearest Neighbor search algorithm ï¼ˆæœ€è¿‘é‚»æœç´¢ç®—æ³•ï¼‰</h3><p>æœ€è¿‘é‚»æœç´¢ç®—æ³•æœ‰å¾ˆå¤šï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥é€‰æ‹© Facebook çš„ FAISS (Facebook AI Similarity Search)ã€‚å®ƒæ—¢èƒ½ç”¨äºé«˜æ•ˆç›¸ä¼¼æ€§æœç´¢ï¼Œåˆèƒ½ä½œä¸ºå¯†é›†å‘é‡å­˜å‚¨åº“ã€‚</p>
<p>FAISSèƒ½å¤Ÿï¼š</p>
<ul>
<li><p>å°†æ–‡æ¡£ã€å›¾åƒç­‰æ•°æ®è½¬æ¢ä¸ºå‘é‡åè¿›è¡Œé«˜æ•ˆçš„ç›¸ä¼¼åº¦æœç´¢</p>
</li>
<li><p>æ”¯æŒå¤šç§è·ç¦»è®¡ç®—æ–¹å¼(å¦‚ä»£ç ä¸­ä½¿ç”¨çš„ä½™å¼¦ç›¸ä¼¼åº¦<code>DistanceStrategy.COSINE</code>)</p>
</li>
<li><p>å¤„ç†å¤§è§„æ¨¡å‘é‡æ•°æ®é›†</p>
</li>
</ul>
<p>FAISSç‰¹ç‚¹ï¼š</p>
<ul>
<li><p>æ”¯æŒ CPU å’Œ GPU åŠ é€Ÿ</p>
</li>
<li><p>æä¾›å¤šç§ç´¢å¼•ç±»å‹ä»¥å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®æ€§</p>
</li>
<li><p>å¯ä»¥æœ¬åœ°ä¿å­˜å’ŒåŠ è½½ç´¢å¼•(å¦‚ä»£ç ä¸­çš„<code>save_local</code>å’Œ<code>load_local</code>)</p>
</li>
<li><p>å†…å­˜æ•ˆç‡é«˜,é€‚åˆå¤„ç†å¤§è§„æ¨¡æ•°æ®</p>
</li>
</ul>
<p>FAISSä¼˜åŠ¿ï¼š</p>
<ul>
<li><p>æœç´¢é€Ÿåº¦å¿«</p>
</li>
<li><p>èµ„æºæ¶ˆè€—ç›¸å¯¹è¾ƒä½</p>
</li>
<li><p>é›†æˆç®€å•,ç‰¹åˆ«æ˜¯ä¸ LangChain ç­‰æ¡†æ¶é…åˆä½¿ç”¨</p>
</li>
<li><p>æ”¯æŒå¢é‡æ›´æ–°ç´¢å¼•</p>
</li>
</ul>
<h3 id="Distances-ï¼ˆè·ç¦»ï¼‰"><a href="#Distances-ï¼ˆè·ç¦»ï¼‰" class="headerlink" title="Distances ï¼ˆè·ç¦»ï¼‰"></a>Distances ï¼ˆè·ç¦»ï¼‰</h3><p>å…³äºå‘é‡é—´çš„è·ç¦»ï¼Œæˆ‘ä»¬å…ˆæ¥å›å¿†ä¸‰ä¸ªæ•°å­¦æ¦‚å¿µã€‚</p>
<h4 id="ç‚¹ç§¯ï¼ˆDot-Productï¼‰ï¼š"><a href="#ç‚¹ç§¯ï¼ˆDot-Productï¼‰ï¼š" class="headerlink" title="ç‚¹ç§¯ï¼ˆDot Productï¼‰ï¼š"></a><strong>ç‚¹ç§¯ï¼ˆDot Productï¼‰ï¼š</strong></h4><p>å¯¹äºä¸¤ä¸ª $$n$$ç»´å‘é‡ $$\mathbf{A} &#x3D; [a_1, a_2, \dots, a_n]$$å’Œ $$\mathbf{B} &#x3D; [b_1, b_2, \dots, b_n]$$ï¼Œå®ƒä»¬çš„ç‚¹ç§¯å®šä¹‰ä¸ºï¼š</p>
<p>$$\mathbf{A} \cdot \mathbf{B} &#x3D; \sum_{i&#x3D;1}^{n} a_i \cdot b_i &#x3D; a_1 b_1 + a_2 b_2 + \cdots + a_n b_n$$</p>
<p><strong>å‡ ä½•æ„ä¹‰</strong>ï¼šç‚¹ç§¯åæ˜ ä¸¤ä¸ªå‘é‡çš„æ–¹å‘å…³ç³»ä¸æ¨¡é•¿çš„ä¹˜ç§¯ï¼Œå³ï¼š</p>
<p>$$\mathbf{A} \cdot \mathbf{B} &#x3D; |\mathbf{A}| \cdot |\mathbf{B}| \cdot \cos\theta$$</p>
<p>å…¶ä¸­ $$\theta$$æ˜¯ä¸¤å‘é‡ä¹‹é—´çš„å¤¹è§’ï¼Œ$$|\mathbf{A}|$$å’Œ $$|\mathbf{B}|$$åˆ†åˆ«ä¸ºå‘é‡çš„æ¨¡é•¿ï¼ˆL2èŒƒæ•°ï¼‰ã€‚</p>
<h4 id="ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine-Similarityï¼‰ï¼š"><a href="#ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine-Similarityï¼‰ï¼š" class="headerlink" title="ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰ï¼š"></a><strong>ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰ï¼š</strong></h4><p>ä½™å¼¦ç›¸ä¼¼åº¦é€šè¿‡å½’ä¸€åŒ–ç‚¹ç§¯æ¥æ¶ˆé™¤å‘é‡é•¿åº¦çš„å½±å“ï¼Œå…¶å®šä¹‰ä¸ºï¼š</p>
<p>$$\text{Cosine Similarity} &#x3D; \cos\theta &#x3D; \frac{\mathbf{A} \cdot \mathbf{B}}{|\mathbf{A}| \cdot |\mathbf{B}|}$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li><p>åˆ†å­ä¸ºä¸¤å‘é‡çš„ç‚¹ç§¯ï¼›</p>
</li>
<li><p>åˆ†æ¯ä¸ºä¸¤å‘é‡æ¨¡é•¿çš„ä¹˜ç§¯ï¼ˆå³å½’ä¸€åŒ–å› å­ï¼‰ã€‚</p>
</li>
</ul>
<p><strong>å‡ ä½•æ„ä¹‰</strong>ï¼šä»…å…³æ³¨å‘é‡æ–¹å‘çš„ä¸€è‡´æ€§ï¼Œå–å€¼èŒƒå›´ä¸º $$[-1, 1]$$ï¼š</p>
<ul>
<li><p><strong>1</strong>ï¼šæ–¹å‘å®Œå…¨ç›¸åŒï¼›</p>
</li>
<li><p><strong>0</strong>ï¼šæ­£äº¤ï¼ˆæ— ç›¸å…³æ€§ï¼‰ï¼›</p>
</li>
<li><p><strong>-1</strong>ï¼šæ–¹å‘å®Œå…¨ç›¸åã€‚</p>
</li>
</ul>
<h4 id="æ¬§å¼è·ç¦»ï¼ˆEuclidean-Distanceï¼‰å…¬å¼"><a href="#æ¬§å¼è·ç¦»ï¼ˆEuclidean-Distanceï¼‰å…¬å¼" class="headerlink" title="æ¬§å¼è·ç¦»ï¼ˆEuclidean Distanceï¼‰å…¬å¼"></a><strong>æ¬§å¼è·ç¦»ï¼ˆEuclidean Distanceï¼‰å…¬å¼</strong></h4><p>ç”¨äºè¡¡é‡ä¸¤ä¸ªå‘é‡åœ¨ç©ºé—´ä¸­çš„ç»å¯¹è·ç¦»ï¼Œæ˜¯æœ€ç›´è§‚çš„å‡ ä½•è·ç¦»åº¦é‡æ–¹å¼ã€‚ </p>
<p><strong>æ•°å­¦å®šä¹‰</strong></p>
<p>å¯¹äº $$n$$ç»´å‘é‡ $$\mathbf{A} &#x3D; [a_1, a_2, \dots, a_n]$$å’Œ $$\mathbf{B} &#x3D; [b_1, b_2, \dots, b_n]$$ï¼Œå…¶æ¬§å¼è·ç¦»å…¬å¼ä¸ºï¼š </p>
<p>$$\text{Euclidean Distance}&#x3D;\sqrt{\sum_{i&#x3D;1}^{n}(a_i-b_i)^2}$$</p>
<p>å³ï¼š  $$\sqrt{(a_1-b_1)^2+(a_2-b_2)^2+\cdots+(a_n-b_n)^2}$$</p>
<p><strong>å‡ ä½•æ„ä¹‰</strong></p>
<p>åœ¨å‡ ä½•ç©ºé—´ä¸­ï¼Œæ¬§å¼è·ç¦»è¡¨ç¤ºä¸¤ç‚¹ä¹‹é—´çš„ç›´çº¿è·ç¦»ã€‚ä¾‹å¦‚ï¼š </p>
<ul>
<li><p><strong>äºŒç»´ç©ºé—´</strong>ä¸­ï¼Œç‚¹ $$(x_1, y_1)$$å’Œ $$(x_2, y_2)$$çš„æ¬§å¼è·ç¦»ä¸º: $$\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$</p>
</li>
<li><p><strong>ä¸‰ç»´ç©ºé—´</strong>ä¸­ï¼Œç‚¹ $$(x_1, y_1, z_1)$$å’Œ $$(x_2, y_2, z_2)$$çš„è·ç¦»ä¸ºï¼š$$\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$$</p>
</li>
</ul>
<p><strong>å…¬å¼å…³ç³»</strong>ï¼š </p>
<p>$$\text{Euclidean Distance}^2&#x3D;|\mathbf{A}|^2+|\mathbf{B}|^2-2|\mathbf{A}||\mathbf{B}|\cos\theta$$ï¼ˆå…¶ä¸­ $$\cos\theta$$ä¸ºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰</p>
<p>å…³äºè·ç¦»ï¼Œè¿˜å¯ä»¥å‚è€ƒè¿™ç¯‡<a target="_blank" rel="noopener" href="https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/#distance-between-embeddings">æŒ‡å—</a>ã€‚å…³é”®æ¦‚å¿µå¦‚ä¸‹ï¼š</p>
<ul>
<li><p>ä½™å¼¦ç›¸ä¼¼åº¦é€šè¿‡è®¡ç®—ä¸¤ä¸ªå‘é‡å¤¹è§’çš„ä½™å¼¦æ¥å¾—åˆ°è¿™ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼æ€§ï¼Œè¿™ç§æ–¹æ³•å…è®¸æˆ‘ä»¬åªæ¯”è¾ƒå‘é‡æ–¹å‘ï¼Œè€Œä¸ç”¨è€ƒè™‘å®ƒä»¬çš„å¤§å°ã€‚ä½¿ç”¨è¿™ç§æ–¹æ³•éœ€è¦å¯¹æ‰€æœ‰å‘é‡è¿›è¡Œå½’ä¸€åŒ–ï¼Œæ¥æŠŠå®ƒä»¬ç¼©æ”¾ä¸ºå•ä½å‘é‡ï¼Œå¯ä»¥ç†è§£æˆå½’ä¸€åŒ–åçš„ç‚¹ç§¯ã€‚</p>
</li>
<li><p>ç‚¹ç§¯è€ƒè™‘äº†å‘é‡çš„é•¿åº¦ï¼Œä½†æœ‰æ—¶ä¼šäº§ç”Ÿä¸å¥½çš„æ•ˆæœï¼Œæœ‰æ—¶å¢åŠ å‘é‡çš„é•¿åº¦å¯èƒ½ä¼šè®©å®ƒå’Œæ‰€æœ‰å…¶ä»–å‘é‡å˜å¾—ç›¸ä¼¼ã€‚</p>
</li>
<li><p><strong>è€Œ</strong>æ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯å‘é‡æœ«ç«¯ä¹‹é—´çš„è·ç¦»ã€‚</p>
</li>
</ul>
<p>æˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„åµŒå…¥æ¨¡å‹åœ¨ä½™å¼¦ç›¸ä¼¼åº¦ä¸‹è¡¨ç°è‰¯å¥½ï¼Œå› æ­¤æˆ‘ä»¬å°±é€‰æ‹©è¿™ä¸ªè·ç¦»ï¼Œå¹¶åœ¨æˆ‘ä»¬çš„åµŒå…¥æ¨¡å‹å’Œ FAISS ç´¢å¼•çš„ <code>distance_strategy</code> å‚æ•°ä¸­è¿›è¡Œè®¾ç½®ã€‚ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ—¶ï¼Œè®°å¾—å¯¹åµŒå…¥å‘é‡è¿›è¡Œå½’ä¸€åŒ–ï¼</p>
<p>ğŸš¨ğŸ‘‡ ä»¥ä¸‹ä»£ç å°±æ˜¯é€šè¿‡åµŒå…¥æ¨¡å‹å°†æ‰€æœ‰æ–‡æœ¬åˆ†å—å‘é‡åŒ–ä¹‹åå­˜å‚¨åˆ°FAISSå‘é‡æ•°æ®åº“ä¸­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">FAISS_INDEX_PATH = <span class="string">&quot;faiss_index&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores.utils <span class="keyword">import</span> DistanceStrategy</span><br><span class="line"></span><br><span class="line">embedding_model = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=EMBEDDING_MODEL_NAME,</span><br><span class="line">    multi_process=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;device&quot;</span>: <span class="string">&quot;cpu&quot;</span>&#125;,</span><br><span class="line">    encode_kwargs=&#123;<span class="string">&quot;normalize_embeddings&quot;</span>: <span class="literal">True</span>&#125;,  <span class="comment"># Set `True` for cosine similarity</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(FAISS_INDEX_PATH):</span><br><span class="line">    KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(FAISS_INDEX_PATH, </span><br><span class="line">                                                 embedding_model, </span><br><span class="line">                                                 allow_dangerous_deserialization=<span class="literal">True</span>  <span class="comment"># æ˜ç¡®å…è®¸ååºåˆ—åŒ–</span></span><br><span class="line">                                                 )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;FAISS ç´¢å¼•å·²å­˜åœ¨ï¼Œå·²ä» <span class="subst">&#123;FAISS_INDEX_PATH&#125;</span> åŠ è½½ã€‚&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(</span><br><span class="line">        docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE</span><br><span class="line">    )</span><br><span class="line">    KNOWLEDGE_VECTOR_DATABASE.save_local(FAISS_INDEX_PATH)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;FAISS ç´¢å¼•ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºå¹¶ä¿å­˜åˆ° <span class="subst">&#123;FAISS_INDEX_PATH&#125;</span>ã€‚&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±è¦å°è¯•åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢æˆ‘ä»¬æŒ‡å®šçš„å†…å®¹äº†ã€‚é¦–å…ˆæˆ‘ä»¬å¯¹æŸ¥è¯¢å†…å®¹ä¹Ÿè¿›è¡ŒåµŒå…¥æ“ä½œï¼Œå¦‚ä¸‹ä»£ç ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Embed a user query in the same space</span></span><br><span class="line">user_query = <span class="string">&quot;How to create a pipeline object?&quot;</span></span><br><span class="line">query_vector = embedding_model.embed_query(user_query)</span><br></pre></td></tr></table></figure>

<p>ä¸ºäº†æ–¹ä¾¿å¯¹æ¯”æ–‡æœ¬å—å‘é‡ä¹‹é—´çš„è·ç¦»ï¼Œæˆ‘ä»¬ä¼šå…ˆå°†ä»–ä»¬å¯è§†åŒ–å‡ºæ¥ã€‚ ä¸ºäº†æ–¹ä¾¿è§‚å¯Ÿï¼Œéœ€è¦åœ¨2ç»´åæ ‡ç³»ä¸­å¯è§†åŒ–ç»“æœï¼Œæˆ‘ä»¬ä½¿ç”¨ PaCMAPæŠŠå—å‘é‡çš„ç»´åº¦ä» 384 ç»´é™åˆ° 2 ç»´ã€‚ä¸‹é¢æ˜¯å¯¹å‘é‡æ•°æ®åº“ä¸­æ‰€æœ‰å‘é‡æ•°æ®ä»¥åŠæŸ¥è¯¢å‘é‡æ•°æ®çš„å¯è§†åŒ–ä»£ç  ã€‚</p>
<blockquote>
<p>ğŸ’¡è¿™é‡Œæˆ‘ä»¬é€‰æ‹©äº† PaCMAP æ¥é™ç»´è€Œä¸æ˜¯å…¶ä»–æŠ€æœ¯ï¼Œæ¯”å¦‚ t-SNE æˆ– UMAPï¼Œ<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s42003-022-03628-x#Abs1">å› ä¸ºPaCMAPæ›´åŠ é«˜æ•ˆï¼Œå¹¶ä¸”èƒ½å¤Ÿä¿ç•™å±€éƒ¨å’Œå…¨å±€ç»“æ„</a>ã€‚</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pacmap</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"></span><br><span class="line">embedding_projector = pacmap.PaCMAP(n_components=<span class="number">2</span>, n_neighbors=<span class="literal">None</span>, MN_ratio=<span class="number">0.5</span>, FP_ratio=<span class="number">2.0</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">embeddings_2d = [</span><br><span class="line">    <span class="built_in">list</span>(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, <span class="number">1</span>)[<span class="number">0</span>]) <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(docs_processed))</span><br><span class="line">] + [query_vector]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the data (the index of transformed data corresponds to the index of the original data)</span></span><br><span class="line">documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=<span class="string">&quot;pca&quot;</span>)</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame.from_dict(</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;x&quot;</span>: documents_projected[i, <span class="number">0</span>],</span><br><span class="line">            <span class="string">&quot;y&quot;</span>: documents_projected[i, <span class="number">1</span>],</span><br><span class="line">            <span class="string">&quot;source&quot;</span>: docs_processed[i].metadata[<span class="string">&quot;source&quot;</span>].split(<span class="string">&quot;/&quot;</span>)[<span class="number">1</span>],</span><br><span class="line">            <span class="string">&quot;extract&quot;</span>: docs_processed[i].page_content[:<span class="number">100</span>] + <span class="string">&quot;...&quot;</span>,</span><br><span class="line">            <span class="string">&quot;symbol&quot;</span>: <span class="string">&quot;circle&quot;</span>,</span><br><span class="line">            <span class="string">&quot;size_col&quot;</span>: <span class="number">4</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(docs_processed))</span><br><span class="line">    ]</span><br><span class="line">    + [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;x&quot;</span>: documents_projected[-<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">            <span class="string">&quot;y&quot;</span>: documents_projected[-<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">            <span class="string">&quot;source&quot;</span>: <span class="string">&quot;User query&quot;</span>,</span><br><span class="line">            <span class="string">&quot;extract&quot;</span>: user_query,</span><br><span class="line">            <span class="string">&quot;size_col&quot;</span>: <span class="number">100</span>,</span><br><span class="line">            <span class="string">&quot;symbol&quot;</span>: <span class="string">&quot;star&quot;</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the embedding</span></span><br><span class="line">fig = px.scatter(</span><br><span class="line">    df,</span><br><span class="line">    x=<span class="string">&quot;x&quot;</span>,</span><br><span class="line">    y=<span class="string">&quot;y&quot;</span>,</span><br><span class="line">    color=<span class="string">&quot;source&quot;</span>,</span><br><span class="line">    hover_data=<span class="string">&quot;extract&quot;</span>,</span><br><span class="line">    size=<span class="string">&quot;size_col&quot;</span>,</span><br><span class="line">    symbol=<span class="string">&quot;symbol&quot;</span>,</span><br><span class="line">    color_discrete_map=&#123;<span class="string">&quot;User query&quot;</span>: <span class="string">&quot;black&quot;</span>&#125;,</span><br><span class="line">    width=<span class="number">1000</span>,</span><br><span class="line">    height=<span class="number">700</span>,</span><br><span class="line">)</span><br><span class="line">fig.update_traces(</span><br><span class="line">    marker=<span class="built_in">dict</span>(opacity=<span class="number">1</span>, line=<span class="built_in">dict</span>(width=<span class="number">0</span>, color=<span class="string">&quot;DarkSlateGrey&quot;</span>)),</span><br><span class="line">    selector=<span class="built_in">dict</span>(mode=<span class="string">&quot;markers&quot;</span>),</span><br><span class="line">)</span><br><span class="line">fig.update_layout(</span><br><span class="line">    legend_title_text=<span class="string">&quot;&lt;b&gt;Chunk source&lt;/b&gt;&quot;</span>,</span><br><span class="line">    title=<span class="string">&quot;&lt;b&gt;2D Projection of Chunk Embeddings via PaCMAP&lt;/b&gt;&quot;</span>,</span><br><span class="line">)</span><br><span class="line">fig.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¦‚æœéœ€è¦ä¿å­˜æˆå›¾ç‰‡ ï¼Œéœ€è¦å…ˆå®‰è£…kaleido</span></span><br><span class="line"><span class="comment"># pip install --upgrade kaleido</span></span><br><span class="line"><span class="comment"># fig.write_image(&quot;embedding_projection.png&quot;)  # ä¿å­˜ä¸ºå›¾ç‰‡</span></span><br></pre></td></tr></table></figure>

<p>å¯è§†åŒ–ç»“æœå¦‚ä¸‹ï¼š</p>
<p><img src="/2025/05/21/ml/llm/rag1/embedding_projection.png"></p>
<p>ä»å›¾ä¸­ä½ å¯ä»¥çœ‹åˆ°å‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰å‘é‡æ•°æ®ï¼ˆæŒ‰ç…§äºŒç»´ç‚¹çš„åæ ‡å½¢å¼å‘ˆç°ï¼‰ï¼Œç‚¹çš„é¢œè‰²è¡¨ç¤ºæ–‡æœ¬åˆ†å—çš„æ¥æºï¼Œå³ç›¸åŒé¢œè‰²å°±è¡¨ç¤ºæ¥æºç›¸åŒçš„æ–‡æœ¬åˆ†å—å‘é‡ã€‚ç”±äºå‘é‡èƒ½å¤Ÿè¡¨è¾¾æ–‡æœ¬åˆ†å—chunkçš„å«ä¹‰ï¼Œå› æ­¤å®ƒä»¬åœ¨å«ä¹‰ä¸Šçš„æ¥è¿‘ç¨‹åº¦å¯ä»¥åæ˜ åœ¨å¯¹åº”å‘é‡çš„æ¥è¿‘ç¨‹åº¦ä¸Šï¼ˆç›¸åŒé¢œè‰²çš„ç‚¹èšé›†åœ¨ä¸€èµ·ï¼‰ã€‚å¦å¤–ï¼Œç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢å‘é‡ä¹Ÿæ˜¾ç¤ºåœ¨å›¾ä¸Šï¼ˆé»‘è‰²æ–¹å—ï¼‰ã€‚</p>
<p>å¦‚æœæˆ‘ä»¬æƒ³è¦æ‰¾åˆ° <code>k</code> ä¸ªå’ŒæŸ¥è¯¢å†…å®¹å«ä¹‰æ¥è¿‘çš„æ–‡æ¡£ï¼Œé‚£æˆ‘ä»¬å°±å¯ä»¥ç›´æ¥é€‰æ‹© <code>k</code> ä¸ªä¸æŸ¥è¯¢å‘é‡æœ€æ¥è¿‘çš„å‘é‡ã€‚åœ¨LangChainçš„å‘é‡æ•°æ®åº“ä¸­ï¼Œè¿™ä¸ªæœç´¢æ“ä½œå¯ä»¥é€šè¿‡æ–¹æ³•<code>vector_database.similarity_search(query)</code> æ¥å®ç°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nStarting retrieval for <span class="subst">&#123;user_query=&#125;</span>...&quot;</span>)</span><br><span class="line">retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n==================================Top document==================================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(retrieved_docs[<span class="number">0</span>].page_content)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;==================================Metadata==================================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(retrieved_docs[<span class="number">0</span>].metadata)</span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºå†…å®¹å¦‚ä¸‹ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Starting retrieval <span class="keyword">for</span> user_query=<span class="string">&#x27;How to create a pipeline object?&#x27;</span>...</span><br><span class="line"></span><br><span class="line">==================================Top document==================================</span><br><span class="line">```</span><br><span class="line">&lt;/tf&gt;</span><br><span class="line">&lt;/frameworkcontent&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## Pipeline</span></span><br><span class="line"></span><br><span class="line">&lt;Youtube <span class="built_in">id</span>=<span class="string">&quot;tiZFewofSLM&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line">The [`pipeline`] is the easiest and fastest way to use a pretrained model <span class="keyword">for</span> inference. You can use the [`pipeline`] out-of-the-box <span class="keyword">for</span> many tasks across different modalities, some of <span class="built_in">which</span> are shown <span class="keyword">in</span> the table below:</span><br><span class="line"></span><br><span class="line">&lt;Tip&gt;</span><br><span class="line"></span><br><span class="line">For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).</span><br><span class="line"></span><br><span class="line">&lt;/Tip&gt;</span><br><span class="line">==================================Metadata==================================</span><br><span class="line">&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;huggingface/transformers/blob/main/docs/source/en/quicktour.md&#x27;</span>, <span class="string">&#x27;start_index&#x27;</span>: 1585&#125;</span><br></pre></td></tr></table></figure>

<h2 id="1-4-é‡æ’åº-Reranking"><a href="#1-4-é‡æ’åº-Reranking" class="headerlink" title="1.4 é‡æ’åº(Reranking)"></a>1.4 é‡æ’åº(Reranking)</h2><p>èªæ˜çš„ä½ å¯èƒ½ä¼šæƒ³åˆ°ï¼Œä¸€ä¸ªæ›´å¥½çš„æ£€ç´¢ç­–ç•¥åº”è¯¥æ˜¯å…ˆæ£€ç´¢å‡ºå°½å¯èƒ½å¤šçš„ç»“æœå†…å®¹ï¼Œç„¶åå†åˆ©ç”¨ä¸€ä¸ªå¼ºå¤§çš„æ£€ç´¢æ¨¡å‹å¯¹ç»“æœè¿›è¡Œé‡æ’åºï¼Œæœ€åå†ä¿ç•™æ’åºå <code>top_k</code> çš„å†…å®¹ã€‚</p>
<p>For this, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.01488">Colbertv2 </a>is a great choice: instead of a bi-encoder like our classical embedding models, it is a cross-encoder that computes more fine-grained interactions between the query tokens and each documentâ€™s tokens.<br>ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é€‰æ‹©äº†<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.01488">Colbertv2</a>ã€‚</p>
<h3 id="Colbertv2"><a href="#Colbertv2" class="headerlink" title="Colbertv2"></a>Colbertv2</h3><p>ColBERT v2.0 æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„ç¥ç»ä¿¡æ¯æ£€ç´¢æ¨¡å‹ï¼Œå®ƒæ˜¯ ColBERT çš„æ”¹è¿›ç‰ˆæœ¬ã€‚ä¸»è¦ç‰¹ç‚¹ï¼š</p>
<ol>
<li><p><strong>å»¶è¿Ÿç¼–ç æŠ€æœ¯</strong></p>
<ul>
<li><p>ä½¿ç”¨ BERT é£æ ¼çš„ç¼–ç å™¨å¯¹æŸ¥è¯¢å’Œæ–‡æ¡£è¿›è¡Œç¼–ç </p>
</li>
<li><p>å°†æŸ¥è¯¢å’Œæ–‡æ¡£çš„äº¤äº’æ¨è¿Ÿåˆ°æœç´¢æ—¶è¿›è¡Œ</p>
</li>
<li><p>æ”¯æŒæ›´ç»†ç²’åº¦çš„ç›¸å…³æ€§åŒ¹é…</p>
</li>
</ul>
</li>
<li><p><strong>æ€§èƒ½ä¼˜åŠ¿</strong></p>
<ul>
<li><p>ç›¸æ¯”ä¼ ç»Ÿçš„æ£€ç´¢æ¨¡å‹å…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§</p>
</li>
<li><p>æ”¯æŒå¿«é€Ÿæ£€ç´¢å’Œé‡æ’åº</p>
</li>
<li><p>åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶è¡¨ç°å‡ºè‰²</p>
</li>
</ul>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong></p>
<ul>
<li><p>æ–‡æ¡£æ£€ç´¢</p>
</li>
<li><p>é—®ç­”ç³»ç»Ÿ</p>
</li>
<li><p>ä¿¡æ¯æ£€ç´¢</p>
</li>
<li><p>é‡æ’åºä»»åŠ¡</p>
</li>
</ul>
</li>
</ol>
<p>ColBERT v2.0 å…³é”®çš„ä¼˜åŠ¿åœ¨äºå®ƒä½¿ç”¨äº†äº¤å‰ç¼–ç å™¨ï¼Œè€Œä¸æ˜¯é€šå¸¸åµŒå…¥æ¨¡å‹çš„åŒç¼–ç å™¨ã€‚</p>
<h3 id="Bi-encoder-vs-Cross-encoder"><a href="#Bi-encoder-vs-Cross-encoder" class="headerlink" title="Bi-encoder vs Cross-encoder"></a>Bi-encoder vs Cross-encoder</h3><p>Bi-encoderï¼ˆåŒç¼–ç å™¨ï¼‰</p>
<ul>
<li><p><strong>å·¥ä½œæ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>åˆ†åˆ«å¯¹æŸ¥è¯¢å’Œæ–‡æ¡£è¿›è¡Œç‹¬ç«‹ç¼–ç </p>
</li>
<li><p>ç”Ÿæˆå›ºå®šç»´åº¦çš„å‘é‡è¡¨ç¤º</p>
</li>
<li><p>é€šè¿‡å‘é‡ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰è®¡ç®—åŒ¹é…ç¨‹åº¦</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bi-encoder ç¤ºä¾‹</span></span><br><span class="line">query_vector = encoder(query)           <span class="comment"># æŸ¥è¯¢ç¼–ç </span></span><br><span class="line">document_vector = encoder(document)     <span class="comment"># æ–‡æ¡£ç¼–ç </span></span><br><span class="line">similarity = cosine_similarity(query_vector, document_vector)</span><br></pre></td></tr></table></figure>

<p>Cross-encoderï¼ˆäº¤å‰ç¼–ç å™¨ï¼‰</p>
<ul>
<li><p><strong>å·¥ä½œæ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>åŒæ—¶å¤„ç†æŸ¥è¯¢å’Œæ–‡æ¡£</p>
</li>
<li><p>ç›´æ¥å¯¹æŸ¥è¯¢-æ–‡æ¡£å¯¹è¿›è¡Œäº¤äº’å»ºæ¨¡</p>
</li>
<li><p>è®¡ç®—æ›´ç»†ç²’åº¦çš„ token çº§åˆ«ç›¸å…³æ€§</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Cross-encoder ç¤ºä¾‹</span></span><br><span class="line">relevance_score = cross_encoder([query, document])  <span class="comment"># ç›´æ¥å¯¹æŸ¥è¯¢å’Œæ–‡æ¡£è¿›è¡Œäº¤äº’ç¼–ç </span></span><br></pre></td></tr></table></figure>

<p><strong>ä¸»è¦ä¼˜åŠ¿å¯¹æ¯”</strong></p>
<ol>
<li><p><strong>è®¡ç®—ç²¾åº¦</strong>ï¼š</p>
<ul>
<li><p>Cross-encoder èƒ½æ•è·æ›´ç»†ç²’åº¦çš„è¯­ä¹‰å…³ç³»</p>
</li>
<li><p>å¯ä»¥è¯†åˆ«æ›´å¤æ‚çš„æŸ¥è¯¢-æ–‡æ¡£åŒ¹é…æ¨¡å¼</p>
</li>
</ul>
</li>
<li><p><strong>è®¡ç®—æ•ˆç‡</strong>ï¼š</p>
<ul>
<li><p>Bi-encoder æ›´é«˜æ•ˆï¼Œå› ä¸ºå¯ä»¥é¢„è®¡ç®—æ–‡æ¡£å‘é‡</p>
</li>
<li><p>Cross-encoder éœ€è¦å®æ—¶è®¡ç®—ï¼Œä½†ç²¾åº¦æ›´é«˜</p>
</li>
</ul>
</li>
</ol>
<p>æˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨ä»£ç é‡Œä½¿ç”¨ <code>ragatouille</code> åº“ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">relevant_docs = knowledge_index.similarity_search(query=user_query, k=<span class="number">30</span>)</span><br><span class="line">relevant_docs = [doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> relevant_docs]  <span class="comment"># Keep only the text</span></span><br><span class="line"><span class="keyword">from</span> ragatouille <span class="keyword">import</span> RAGPretrainedModel</span><br><span class="line"></span><br><span class="line">RERANKER = RAGPretrainedModel.from_pretrained(<span class="string">&quot;colbert-ir/colbertv2.0&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&gt; Reranking documents...&quot;</span>)</span><br><span class="line">relevant_docs = reranker.rerank(user_query, relevant_docs, k=<span class="number">5</span>)</span><br><span class="line">relevant_docs = [doc[<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> doc <span class="keyword">in</span> relevant_docs]</span><br><span class="line">relevant_docs = relevant_docs[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<h1 id="2-Reader-LLM-ğŸ’¬"><a href="#2-Reader-LLM-ğŸ’¬" class="headerlink" title="2. Reader - LLM ğŸ’¬"></a>2. Reader - LLM ğŸ’¬</h1><p>åœ¨è¿™ä¸€éƒ¨åˆ†ï¼ŒLLM Reader ä¼šè¯»å–ä¸Šé¢æ£€ç´¢åˆ°çš„å†…å®¹æ¥å½¢æˆæœ€ç»ˆçš„ç­”æ¡ˆã€‚åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œå¯ä»¥è°ƒæ•´çš„å­æ­¥éª¤æœ‰å¾ˆå¤šï¼š</p>
<ol>
<li><p>æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹è¢«èšåˆåˆ°â€œä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰â€ä¸­ï¼Œæœ‰å¾ˆå¤šå¤„ç†æ–¹å¼å¯ä¾›é€‰æ‹©ï¼Œæ¯”å¦‚<em>prompt compression</em>ã€‚</p>
</li>
<li><p>ä¸Šä¸‹æ–‡å’Œç”¨æˆ·çš„æŸ¥è¯¢è¢«èšåˆåœ¨ä¸€ä¸ªprompté‡Œï¼Œæäº¤ç»™ LLM æ¥ç”Ÿæˆæœ€ç»ˆçš„ç­”æ¡ˆã€‚</p>
</li>
</ol>
<h2 id="2-1-Reader-model"><a href="#2-1-Reader-model" class="headerlink" title="2.1. Reader model"></a>2.1. Reader model</h2><p>åœ¨é€‰æ‹©Reader Model ä¹Ÿå°±æ˜¯ LLM æ—¶éœ€è¦è€ƒè™‘å¦‚ä¸‹å‡ ä¸ªæ–¹é¢ï¼š</p>
<ul>
<li>æˆ‘ä»¬æä¾›ç»™Reader Modelçš„prompt é•¿åº¦å—é™äºæ¨¡å‹çš„<code>max_seq_length</code> å‚æ•°ï¼Œpromptä¸­ä¸»è¦çš„å†…å®¹å°±æ˜¯Retrieverè¾“å‡ºçš„æ£€ç´¢ç»“æœï¼Œå‰æ–‡ä¸­çš„ä»£ç æˆ‘ä»¬é€‰æ‹©äº† 5ï¼ˆ<code>k=5</code>ï¼‰ä¸ªæœ€æ¥è¿‘çš„å†…å®¹ï¼Œæ¯ä¸ªæ˜¯ç”± 512ï¼ˆ<code>chunk_size=512</code>ï¼‰ ä¸ªtokenç»„æˆï¼Œå› æ­¤æˆ‘ä»¬é¢„ä¼°éœ€è¦LLMè‡³å°‘æ”¯æŒçš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸º 4kã€‚</li>
</ul>
<blockquote>
<p>ä¸ºä»€ä¹ˆæ˜¯4Kï¼Ÿ å¦‚æœæœ‰5ä¸ªæ–‡æ¡£ï¼Œæ¯ä¸ª512ä¸ªtokenï¼Œé‚£ä¹ˆä»…æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å°±åªæœ‰2,560ä¸ªtokenï¼ˆ5 Ã— 512 &#x3D; 2,560ï¼‰ã€‚4K tokensè¯´æ˜éœ€è¦è€ƒè™‘é™¤æ£€ç´¢æ–‡æ¡£ä¹‹å¤–çš„å…¶ä»–ç»„ä»¶ï¼š</p>
<ol>
<li><p><strong>æ£€ç´¢ä¸Šä¸‹æ–‡</strong>ï¼š2,560 tokensï¼ˆ5 Ã— 512ï¼‰</p>
</li>
<li><p><strong>ç”¨æˆ·æŸ¥è¯¢&#x2F;é—®é¢˜</strong>ï¼šå¤§çº¦50-200 tokens</p>
</li>
<li><p><strong>ç³»ç»Ÿæç¤º&#x2F;æŒ‡ä»¤</strong>ï¼šå¯èƒ½200-500 tokens</p>
</li>
<li><p><strong>æ ¼å¼åŒ–&#x2F;åˆ†éš”ç¬¦</strong>ï¼šæœ€å°å¼€é”€</p>
</li>
<li><p><strong>å“åº”ç”Ÿæˆç¼“å†²åŒº</strong>ï¼š500-1000 tokens</p>
</li>
</ol>
<p>æ‰€ä»¥4K tokensåœ¨ä»…æ£€ç´¢æ–‡æ¡£æ‰€éœ€çš„æœ€å°2,560 tokensåŸºç¡€ä¸Šæä¾›äº†åˆç†çš„å®‰å…¨è¾¹é™…ã€‚è¿™è€ƒè™‘äº†å®Œæ•´çš„æç¤ºç»“æ„ï¼Œå¹¶ç¡®ä¿æ¨¡å‹æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡çª—å£æ¥è¿›è¡Œè¾“å…¥å¤„ç†å’Œå“åº”ç”Ÿæˆã€‚</p>
<p>ä¸è¿‡ï¼Œå¦‚æœä½ çš„æ£€ç´¢ä¸Šä¸‹æ–‡çœŸçš„å›ºå®šåœ¨2,560 tokensï¼Œè€Œå…¶ä»–ç»„ä»¶å¾ˆå°‘ï¼Œä½ å¯èƒ½å¯ä»¥ä½¿ç”¨æ›´å°çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆæ¯”å¦‚3Kï¼‰ã€‚é€‰æ‹©4Kä¼¼ä¹æ˜¯ä¸€ä¸ªä¿å®ˆçš„ä¼°è®¡ï¼Œä¸ºæç¤ºå˜åŒ–æä¾›äº†ä½™é‡ï¼Œç¡®ä¿å¯é è¿è¡Œã€‚</p>
</blockquote>
<ul>
<li>reader model çš„é€‰æ‹©</li>
</ul>
<p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† <a target="_blank" rel="noopener" href="https://hf-mirror.com/HuggingFaceH4/zephyr-7b-beta"><code>HuggingFaceH4/zephyr-7b-beta</code></a> ï¼Œä¸€ä¸ªå°å·§è€Œå¼ºå¤§çš„æ¨¡å‹ã€‚ç°åœ¨æ¯å‘¨éƒ½ä¼šæœ‰è®¸å¤šæ¨¡å‹å‘å¸ƒï¼Œä½ å¯ä»¥æŠŠè¿™ä¸ªæ¨¡å‹æ›¿æ¢ä¸ºä½ æƒ³è¦çš„æœ€æ–°æœ€å¥½çš„æ¨¡å‹ã€‚è·Ÿè¸ªå¼€æº LLM çš„æœ€ä½³æ–¹æ³•æ˜¯æŸ¥çœ‹ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open-source LLM leaderboard</a>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig</span><br><span class="line"></span><br><span class="line">READER_MODEL_NAME = <span class="string">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸ºäº†åŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œæˆ‘ä»¬åŠ è½½è¿™ä¸ªæ¨¡å‹çš„é‡åŒ–ç‰ˆæœ¬</span></span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>, <span class="comment"># 4bit é‡åŒ–</span></span><br><span class="line">    bnb_4bit_use_double_quant=<span class="literal">True</span>, <span class="comment"># åŒé‡é‡åŒ–ï¼Œè¿›ä¸€æ­¥å‹ç¼©é‡åŒ–å‚æ•°</span></span><br><span class="line">    <span class="comment"># NF4ï¼šä¸“ä¸ºç¥ç»ç½‘ç»œæƒé‡åˆ†å¸ƒä¼˜åŒ–çš„4ä½æ•°æ®ç±»å‹</span></span><br><span class="line">    <span class="comment"># ç›¸æ¯”ä¼ ç»Ÿçš„å‡åŒ€é‡åŒ–ï¼ˆfp4ï¼‰ï¼ŒNF4èƒ½æ›´å¥½åœ°å¤„ç†æƒé‡çš„æ­£æ€åˆ†å¸ƒç‰¹æ€§</span></span><br><span class="line">    <span class="comment"># åœ¨ç›¸åŒå‹ç¼©ç‡ä¸‹æä¾›æ›´å¥½çš„æ¨¡å‹æ€§èƒ½</span></span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>, <span class="comment"># æŒ‡å®šé‡åŒ–ç±»å‹ä¸ºNF4ï¼ˆNormalFloat4ï¼‰</span></span><br><span class="line">    bnb_4bit_compute_dtype=torch.bfloat16,</span><br><span class="line">)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)</span><br><span class="line"></span><br><span class="line">READER_LLM = pipeline(</span><br><span class="line">    model=model,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    task=<span class="string">&quot;text-generation&quot;</span>,</span><br><span class="line">    do_sample=<span class="literal">True</span>,</span><br><span class="line">    temperature=<span class="number">0.2</span>,</span><br><span class="line">    repetition_penalty=<span class="number">1.1</span>,</span><br><span class="line">    return_full_text=<span class="literal">False</span>,</span><br><span class="line">    max_new_tokens=<span class="number">500</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># READER_LLM(&quot;What is 4+4? Answer:&quot;)</span></span><br></pre></td></tr></table></figure>

<h2 id="2-2-Prompt"><a href="#2-2-Prompt" class="headerlink" title="2.2. Prompt"></a>2.2. Prompt</h2><p>ä¸‹é¢æ˜¯æˆ‘ä»¬æä¾›ç»™ Reader LLM çš„ RAG æç¤ºè¯æ¨¡æ¿ï¼Œ åœ¨æ¨¡æ¿ä¸­æˆ‘ä»¬æŒ‡å®šäº†ä¸Šä¸‹æ–‡<code>&#123;context&#125;</code>å’Œç”¨æˆ·é—®é¢˜<code>&#123;question&#125;</code>è¿™ä¸¤ä¸ªéœ€è¦å¡«å……çš„å˜é‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">prompt_in_chat_format = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&quot;&quot;Using the information contained in the context,</span></span><br><span class="line"><span class="string">give a comprehensive answer to the question.</span></span><br><span class="line"><span class="string">Respond only to the question asked, response should be concise and relevant to the question.</span></span><br><span class="line"><span class="string">Provide the number of the source document when relevant.</span></span><br><span class="line"><span class="string">If the answer cannot be deduced from the context, do not give an answer.&quot;&quot;&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&quot;&quot;Context:</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">Now here is the question you need to answer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;question&#125;&quot;&quot;&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line">RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(</span><br><span class="line">    prompt_in_chat_format, tokenize=<span class="literal">False</span>, add_generation_prompt=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(RAG_PROMPT_TEMPLATE)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;|system|&gt;</span><br><span class="line">Using the information contained <span class="keyword">in</span> the context, </span><br><span class="line">give a comprehensive answer to the question.</span><br><span class="line">Respond only to the question asked, response should be concise and relevant to the question.</span><br><span class="line">Provide the number of the <span class="built_in">source</span> document when relevant.</span><br><span class="line">If the answer cannot be deduced from the context, <span class="keyword">do</span> not give an answer.</span><br><span class="line">&lt;|user|&gt;</span><br><span class="line">Context:</span><br><span class="line">&amp;#123;context&#125;</span><br><span class="line">---</span><br><span class="line">Now here is the question you need to answer.</span><br><span class="line"></span><br><span class="line">Question: &amp;#123;question&#125;</span><br><span class="line">&lt;|assistant|&gt;</span><br></pre></td></tr></table></figure>

<p>æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹è¿™ä¸ªæ¨¡å‹çš„æ•ˆæœ, æˆ‘ä»¬éœ€è¦æŠŠä¸Šé¢çš„æ¨¡æ¿formatä¸€ä¸‹å†è¾“å…¥ç»™æ¨¡å‹ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">retrieved_docs_text = [doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> retrieved_docs]  <span class="comment"># We only need the text of the documents</span></span><br><span class="line">context = <span class="string">&quot;\nExtracted documents:\n&quot;</span></span><br><span class="line">context += <span class="string">&quot;&quot;</span>.join([<span class="string">f&quot;Document <span class="subst">&#123;<span class="built_in">str</span>(i)&#125;</span>:::\n&quot;</span> + doc <span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(retrieved_docs_text)])</span><br><span class="line"></span><br><span class="line">final_prompt = RAG_PROMPT_TEMPLATE.<span class="built_in">format</span>(question=<span class="string">&quot;How to create a pipeline object?&quot;</span>, context=context)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Redact an answer</span></span><br><span class="line">answer = READER_LLM(final_prompt)[<span class="number">0</span>][<span class="string">&quot;generated_text&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h1 id="3-å†…å®¹æ•´åˆ"><a href="#3-å†…å®¹æ•´åˆ" class="headerlink" title="3. å†…å®¹æ•´åˆ"></a>3. å†…å®¹æ•´åˆ</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">answer_with_rag</span>(<span class="params"></span></span><br><span class="line"><span class="params">    question: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">    llm: Pipeline,</span></span><br><span class="line"><span class="params">    knowledge_index: FAISS,</span></span><br><span class="line"><span class="params">    reranker: <span class="type">Optional</span>[RAGPretrainedModel] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    num_retrieved_docs: <span class="built_in">int</span> = <span class="number">30</span>,</span></span><br><span class="line"><span class="params">    num_docs_final: <span class="built_in">int</span> = <span class="number">5</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">str</span>, <span class="type">List</span>[LangchainDocument]]:</span><br><span class="line">    <span class="comment"># Gather documents with retriever</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; Retrieving documents...&quot;</span>)</span><br><span class="line">    relevant_docs = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)</span><br><span class="line">    relevant_docs = [doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> relevant_docs]  <span class="comment"># Keep only the text</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optionally rerank results</span></span><br><span class="line">    <span class="keyword">if</span> reranker:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&gt; Reranking documents...&quot;</span>)</span><br><span class="line">        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)</span><br><span class="line">        relevant_docs = [doc[<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> doc <span class="keyword">in</span> relevant_docs]</span><br><span class="line"></span><br><span class="line">    relevant_docs = relevant_docs[:num_docs_final]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the final prompt</span></span><br><span class="line">    context = <span class="string">&quot;\nExtracted documents:\n&quot;</span></span><br><span class="line">    context += <span class="string">&quot;&quot;</span>.join([<span class="string">f&quot;Document <span class="subst">&#123;<span class="built_in">str</span>(i)&#125;</span>:::\n&quot;</span> + doc <span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(relevant_docs)])</span><br><span class="line"></span><br><span class="line">    final_prompt = RAG_PROMPT_TEMPLATE.<span class="built_in">format</span>(question=question, context=context)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Redact an answer</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; Generating answer...&quot;</span>)</span><br><span class="line">    answer = llm(final_prompt)[<span class="number">0</span>][<span class="string">&quot;generated_text&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> answer, relevant_docs</span><br></pre></td></tr></table></figure>

<p>è®©æˆ‘ä»¬çœ‹çœ‹ RAG æ€ä¹ˆå›ç­”ç”¨æˆ·çš„æé—®ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">question = <span class="string">&quot;how to create a pipeline object?&quot;</span></span><br><span class="line"></span><br><span class="line">answer, relevant_docs = answer_with_rag(question, READER_LLM, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER)</span><br></pre></td></tr></table></figure>

<p>=&gt; Retrieving documentsâ€¦</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;==================================Answer==================================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;answer&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;==================================Source docs==================================&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(relevant_docs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Document <span class="subst">&#123;i&#125;</span>------------------------------------------------------------&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(doc)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line">==================================Answer==================================</span><br><span class="line">To create a pipeline object, follow these steps:</span><br><span class="line"></span><br><span class="line">1. Import the `pipeline` function from the `transformers` module:</span><br><span class="line"></span><br><span class="line">   ```python</span><br><span class="line">   from transformers import pipeline</span><br><span class="line">   ```</span><br><span class="line"></span><br><span class="line">2. Choose the task you want to perform, such as object detection, sentiment analysis, or image generation, and pass it as an argument to the `pipeline` function:</span><br><span class="line"></span><br><span class="line">   - For object detection:</span><br><span class="line"></span><br><span class="line">     ```python</span><br><span class="line">     &gt;&gt;&gt; object_detector = pipeline(&#x27;object-detection&#x27;)</span><br><span class="line">     &gt;&gt;&gt; object_detector(image)</span><br><span class="line">     [&amp;#123;&#x27;score&#x27;: 0.9982201457023621,</span><br><span class="line">       &#x27;label&#x27;:&#x27;remote&#x27;,</span><br><span class="line">       &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 40, &#x27;ymin&#x27;: 70, &#x27;xmax&#x27;: 175, &#x27;ymax&#x27;: 117&#125;&#125;,</span><br><span class="line">     ...]</span><br><span class="line">     ```</span><br><span class="line"></span><br><span class="line">   - For sentiment analysis:</span><br><span class="line"></span><br><span class="line">     ```python</span><br><span class="line">     &gt;&gt;&gt; classifier = pipeline(&quot;sentiment-analysis&quot;)</span><br><span class="line">     &gt;&gt;&gt; classifier(&quot;This is a great product!&quot;)</span><br><span class="line">     &amp;#123;&#x27;labels&#x27;: [&#x27;POSITIVE&#x27;],&#x27;scores&#x27;: tensor([0.9999], device=&#x27;cpu&#x27;, dtype=torch.float32)&#125;</span><br><span class="line">     ```</span><br><span class="line"></span><br><span class="line">   - For image generation:</span><br><span class="line"></span><br><span class="line">     ```python</span><br><span class="line">     &gt;&gt;&gt; image = pipeline(</span><br><span class="line">    ... &quot;stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k&quot;</span><br><span class="line">    ... ).images[0]</span><br><span class="line">     &gt;&gt;&gt; image</span><br><span class="line">     PILImage mode RGB size 7680x4320 at 0 DPI</span><br><span class="line">     ```</span><br><span class="line">Note that the exact syntax may vary depending on the specific pipeline being used. Refer to the documentation for more details on how to use each pipeline.</span><br><span class="line"></span><br><span class="line">In general, the process involves importing the necessary modules, selecting the desired pipeline task, and passing it to the `pipeline` function along with any required arguments. The resulting pipeline object can then be used to perform the selected task on input data.</span><br><span class="line">==================================Source docs==================================</span><br><span class="line">Document 0------------------------------------------------------------</span><br><span class="line"># Allocate a pipeline for object detection</span><br><span class="line">&gt;&gt;&gt; object_detector = pipeline(&#x27;object-detection&#x27;)</span><br><span class="line">&gt;&gt;&gt; object_detector(image)</span><br><span class="line">[&amp;#123;&#x27;score&#x27;: 0.9982201457023621,</span><br><span class="line">  &#x27;label&#x27;: &#x27;remote&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 40, &#x27;ymin&#x27;: 70, &#x27;xmax&#x27;: 175, &#x27;ymax&#x27;: 117&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9960021376609802,</span><br><span class="line">  &#x27;label&#x27;: &#x27;remote&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 333, &#x27;ymin&#x27;: 72, &#x27;xmax&#x27;: 368, &#x27;ymax&#x27;: 187&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9954745173454285,</span><br><span class="line">  &#x27;label&#x27;: &#x27;couch&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 0, &#x27;ymin&#x27;: 1, &#x27;xmax&#x27;: 639, &#x27;ymax&#x27;: 473&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9988006353378296,</span><br><span class="line">  &#x27;label&#x27;: &#x27;cat&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 13, &#x27;ymin&#x27;: 52, &#x27;xmax&#x27;: 314, &#x27;ymax&#x27;: 470&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9986783862113953,</span><br><span class="line">  &#x27;label&#x27;: &#x27;cat&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 345, &#x27;ymin&#x27;: 23, &#x27;xmax&#x27;: 640, &#x27;ymax&#x27;: 368&#125;&#125;]</span><br><span class="line">Document 1------------------------------------------------------------</span><br><span class="line"># Allocate a pipeline for object detection</span><br><span class="line">&gt;&gt;&gt; object_detector = pipeline(&#x27;object_detection&#x27;)</span><br><span class="line">&gt;&gt;&gt; object_detector(image)</span><br><span class="line">[&amp;#123;&#x27;score&#x27;: 0.9982201457023621,</span><br><span class="line">  &#x27;label&#x27;: &#x27;remote&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 40, &#x27;ymin&#x27;: 70, &#x27;xmax&#x27;: 175, &#x27;ymax&#x27;: 117&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9960021376609802,</span><br><span class="line">  &#x27;label&#x27;: &#x27;remote&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 333, &#x27;ymin&#x27;: 72, &#x27;xmax&#x27;: 368, &#x27;ymax&#x27;: 187&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9954745173454285,</span><br><span class="line">  &#x27;label&#x27;: &#x27;couch&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 0, &#x27;ymin&#x27;: 1, &#x27;xmax&#x27;: 639, &#x27;ymax&#x27;: 473&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9988006353378296,</span><br><span class="line">  &#x27;label&#x27;: &#x27;cat&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 13, &#x27;ymin&#x27;: 52, &#x27;xmax&#x27;: 314, &#x27;ymax&#x27;: 470&#125;&#125;,</span><br><span class="line"> &amp;#123;&#x27;score&#x27;: 0.9986783862113953,</span><br><span class="line">  &#x27;label&#x27;: &#x27;cat&#x27;,</span><br><span class="line">  &#x27;box&#x27;: &amp;#123;&#x27;xmin&#x27;: 345, &#x27;ymin&#x27;: 23, &#x27;xmax&#x27;: 640, &#x27;ymax&#x27;: 368&#125;&#125;]</span><br><span class="line">Document 2------------------------------------------------------------</span><br><span class="line">Start by creating an instance of [`pipeline`] and specifying a task you want to use it for. In this guide, you&#x27;ll use the [`pipeline`] for sentiment analysis as an example:</span><br><span class="line"></span><br><span class="line">```py</span><br><span class="line">&gt;&gt;&gt; from transformers import pipeline</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; classifier = pipeline(&quot;sentiment-analysis&quot;)</span><br><span class="line">Document 3------------------------------------------------------------</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">## Add the pipeline to ğŸ¤— Transformers</span><br><span class="line"></span><br><span class="line">If you want to contribute your pipeline to ğŸ¤— Transformers, you will need to add a new module in the `pipelines` submodule</span><br><span class="line">with the code of your pipeline, then add it to the list of tasks defined in `pipelines/__init__.py`.</span><br><span class="line"></span><br><span class="line">Then you will need to add tests. Create a new file `tests/test_pipelines_MY_PIPELINE.py` with examples of the other tests.</span><br><span class="line"></span><br><span class="line">The `run_pipeline_test` function will be very generic and run on small random models on every possible</span><br><span class="line">architecture as defined by `model_mapping` and `tf_model_mapping`.</span><br><span class="line"></span><br><span class="line">This is very important to test future compatibility, meaning if someone adds a new model for</span><br><span class="line">`XXXForQuestionAnswering` then the pipeline test will attempt to run on it. Because the models are random it&#x27;s</span><br><span class="line">impossible to check for actual values, that&#x27;s why there is a helper `ANY` that will simply attempt to match the</span><br><span class="line">output of the pipeline TYPE.</span><br><span class="line"></span><br><span class="line">You also *need* to implement 2 (ideally 4) tests.</span><br><span class="line"></span><br><span class="line">- `test_small_model_pt` : Define 1 small model for this pipeline (doesn&#x27;t matter if the results don&#x27;t make sense)</span><br><span class="line">  and test the pipeline outputs. The results should be the same as `test_small_model_tf`.</span><br><span class="line">- `test_small_model_tf` : Define 1 small model for this pipeline (doesn&#x27;t matter if the results don&#x27;t make sense)</span><br><span class="line">  and test the pipeline outputs. The results should be the same as `test_small_model_pt`.</span><br><span class="line">- `test_large_model_pt` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to</span><br><span class="line">  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make</span><br><span class="line">  sure there is no drift in future releases.</span><br><span class="line">- `test_large_model_tf` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to</span><br><span class="line">  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make</span><br><span class="line">  sure there is no drift in future releases.</span><br><span class="line">Document 4------------------------------------------------------------</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">2. Pass a prompt to the pipeline to generate an image:</span><br><span class="line"></span><br><span class="line">```py</span><br><span class="line">image = pipeline(</span><br><span class="line">        &quot;stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k&quot;</span><br><span class="line">).images[0]</span><br><span class="line">image</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>Buy me a coffee</div>
  <button>
    Donate
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.jpg" alt="GalaxyGuan WeChat Pay">
        <span>WeChat Pay</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>GalaxyGuan
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/" title="RAGå…¨æµç¨‹è§£æ">https://galaxyguan12.github.io/2025/05/21/ml/llm/rag1/</a>
  </li>
  <li class="post-copyright-license">
      <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/LLM/" rel="tag"># LLM</a>
              <a href="/tags/RAG/" rel="tag"># RAG</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/05/19/cpp/cmake_mac/" rel="prev" title="C++ Mac æ‰“åŒ…è¿è¡Œæ–¹æ¡ˆï¼ˆcmakeï¼‰">
                  <i class="fa fa-angle-left"></i> C++ Mac æ‰“åŒ…è¿è¡Œæ–¹æ¡ˆï¼ˆcmakeï¼‰
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/05/29/cpp/cmake_win/" rel="next" title="C++ Windows æ‰“åŒ…exeè¿è¡Œæ–¹æ¡ˆï¼ˆcmakeï¼‰">
                  C++ Windows æ‰“åŒ…exeè¿è¡Œæ–¹æ¡ˆï¼ˆcmakeï¼‰ <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">GalaxyGuan</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
